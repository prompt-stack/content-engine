"""
Image Generation Service
Supports: OpenAI DALL-E 3 / GPT Image 1, Google Gemini 2.5 Flash Image (nano-banana), Imagen 4
Updated: September 2025 with latest models
"""

import os
import requests
import base64
from pathlib import Path
from typing import Optional, Literal
from openai import AsyncOpenAI
from google import genai
from google.genai import types

from app.core.config import settings


class ImageGenerationService:
    """Service for generating images using various AI providers"""

    def __init__(self, provider: Literal["openai", "gemini"]):
        self.provider = provider
        if provider == "openai":
            if not settings.OPENAI_API_KEY:
                raise ValueError("OpenAI API key not configured")
            self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
        elif provider == "gemini":
            if not settings.GEMINI_API_KEY:
                raise ValueError("Gemini API key not configured")
            self.client = genai.Client(api_key=settings.GEMINI_API_KEY)
        else:
            raise ValueError(f"Unsupported provider: {provider}")

    async def generate_dalle(
        self,
        prompt: str,
        model: str = "dall-e-3",
        size: str = "1024x1024",
        quality: str = "standard",
        style: str = "vivid"
    ) -> dict:
        """
        Generate image using OpenAI DALL-E

        Args:
            prompt: Text description of the image
            model: "dall-e-3" or "dall-e-2"
            size: Image size (dall-e-3: "1024x1024", "1792x1024", "1024x1792")
            quality: "standard" or "hd" (dall-e-3 only)
            style: "vivid" or "natural" (dall-e-3 only)

        Returns:
            dict with image_url, revised_prompt, size
        """
        if model == "dall-e-3":
            response = await self.client.images.generate(
                model=model,
                prompt=prompt,
                size=size,
                quality=quality,
                style=style,
                n=1
            )
        else:  # dall-e-2
            response = await self.client.images.generate(
                model=model,
                prompt=prompt,
                size=size,
                n=1
            )

        image_url = response.data[0].url
        revised_prompt = getattr(response.data[0], 'revised_prompt', prompt)

        return {
            "image_url": image_url,
            "revised_prompt": revised_prompt,
            "size": size,
            "model": model,
            "provider": "openai"
        }

    def generate_gemini(
        self,
        prompt: str,
        temperature: float = 1.0
    ) -> dict:
        """
        Generate image using Google Gemini 2.5 Flash Image (nano-banana)

        Latest model: gemini-2.5-flash-image-preview (August 2025)
        Features: Image blending, character consistency, world knowledge
        Pricing: $0.039 per image

        Args:
            prompt: Text description of the image
            temperature: Creativity level (0.0-2.0, higher = more creative)

        Returns:
            dict with image_data (base64), mime_type
        """
        model = "gemini-2.5-flash-image-preview"

        contents = [
            types.Content(
                role="user",
                parts=[types.Part.from_text(text=prompt)],
            ),
        ]

        config = types.GenerateContentConfig(
            response_modalities=["IMAGE"],
            temperature=temperature,
        )

        response = self.client.models.generate_content(
            model=model,
            contents=contents,
            config=config,
        )

        # Extract first generated image
        if response.candidates:
            for candidate in response.candidates:
                if candidate.content and candidate.content.parts:
                    for part in candidate.content.parts:
                        if hasattr(part, 'inline_data') and part.inline_data:
                            image_data = part.inline_data.data
                            mime_type = part.inline_data.mime_type

                            # Convert to base64 string if bytes
                            if isinstance(image_data, bytes):
                                image_data = base64.b64encode(image_data).decode('utf-8')

                            return {
                                "image_data": image_data,
                                "mime_type": mime_type,
                                "model": model,
                                "provider": "gemini"
                            }

        raise Exception("No image generated by Gemini")

    async def generate(
        self,
        prompt: str,
        **kwargs
    ) -> dict:
        """
        Generate image using configured provider

        Args:
            prompt: Text description
            **kwargs: Provider-specific parameters

        Returns:
            dict with generation results
        """
        if self.provider == "openai":
            return await self.generate_dalle(prompt, **kwargs)
        elif self.provider == "gemini":
            return self.generate_gemini(prompt, **kwargs)
        else:
            raise ValueError(f"Unsupported provider: {self.provider}")


async def generate_image(
    prompt: str,
    provider: str = "openai",
    **kwargs
) -> dict:
    """
    Convenience function to generate image

    Args:
        prompt: Image description
        provider: "openai" or "gemini"
        **kwargs: Provider-specific parameters

    Returns:
        Generation results
    """
    service = ImageGenerationService(provider=provider)
    return await service.generate(prompt, **kwargs)